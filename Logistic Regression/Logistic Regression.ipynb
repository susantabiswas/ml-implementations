{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Logistic Regression for cat classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a cat classification problem, where the task is to classify a picture as a cat or non-cat picture.\n",
    "<br>Output y = 1 if the picture is of a cat \n",
    "<br>Output y = 0 if the picture is not of a cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset_utility as du\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains cat and non-cat pictures and the labels are 0 or 1.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape:(209, 64, 64, 3)\n",
      "Training output shape:(209,)\n",
      "Test features shape:(50, 64, 64, 3)\n",
      "Test output shape:(50,)\n"
     ]
    }
   ],
   "source": [
    "# load the data set\n",
    "test_loc = r'datasets\\train_catvsnoncat.h5'\n",
    "train_loc = r'datasets\\test_catvsnoncat.h5'\n",
    "\n",
    "train_X, train_y, test_X, test_y = du.load_data2(train_loc, test_loc)\n",
    "\n",
    "print('Training features shape:'+ str(train_X.shape))\n",
    "print('Training output shape:'+ str(train_y.shape))\n",
    "print('Test features shape:'+ str(test_X.shape))\n",
    "print('Test output shape:'+ str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) <u>Reshape the matrices.</u>\n",
    "### 2) <u>Flatten the feature matrix and create one hot matrix for output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape the output matrices to avoid it being treated as rank 1 matrix\n",
    "train_y = np.reshape(train_y, (train_y.shape[0],1))\n",
    "test_y = np.reshape(test_y, (test_y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# noramalize the features\n",
    "train_X, test_X = du.normalize_data( train_X, test_X)\n",
    "\n",
    "# flatten the feature matrix\n",
    "train_X, test_X = du.unroll_features(train_X, test_X)\n",
    "\n",
    "# transpose the label matrices to match the dimension format\n",
    "train_y = train_y.T\n",
    "test_y = test_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-739405ce6044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check the dimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training features shape:'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training output shape:'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test features shape:'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test output shape:'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# check the dimensions\n",
    "print('Training features shape:'+ str(train_X.shape))\n",
    "print('Training output shape:'+ str(train_y.shape))\n",
    "print('Test features shape:'+ str(test_X.shape))\n",
    "print('Test output shape:'+ str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weight and bias parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n):\n",
    "    '''\n",
    "    for initializing the weight and bias parameters with zero value\n",
    "    \n",
    "    Arguments:\n",
    "        n: no. of input features\n",
    "    Returns:\n",
    "        parameters: (dict) zero initialized weight and bias parameters \n",
    "    '''\n",
    "    parameters = {}\n",
    "    # we will use zero initialization\n",
    "    parameters['W'] = np.zeros((n,1), dtype = np.float64)\n",
    "    # bias\n",
    "    parameters['b'] = 0\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for doing the sigmoid function\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    for computing the sigmoid function\n",
    "    \n",
    "    Arguments:\n",
    "        z: linear input\n",
    "    Returns:\n",
    "        A: (float) sigmoid output\n",
    "    '''\n",
    "    A = (1/ (1 + np.exp(-z)))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for computing the logistic error\n",
    "def compute_cost(train_y, y_hat):\n",
    "    '''\n",
    "    for computing the mean loss (cost) for logistic regression\n",
    "    \n",
    "    Arguments:\n",
    "        train_y:(numpy matrix) contains the correct output labels for m training examples\n",
    "        y_hat:(numpy matrix) contains the sigmoid output values for m training examples\n",
    "    Returns:\n",
    "        cost: (float) cost value for m training examples\n",
    "    '''\n",
    "    cost = (1/train_y.shape[1]) * np.sum( -train_y*np.log(y_hat) - (1-train_y)*np.log(1 - y_hat) )\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(parameters, train_X, train_y, y_hat, learning_rate):\n",
    "    '''\n",
    "    for doing gradient descent and updating the weights\n",
    "    \n",
    "    Arguments:\n",
    "        parameters: (dict) contains the learned weight and bias parameters\n",
    "        train_X:(numpy matrix) contains the input features for m training examples\n",
    "        train_y:(numpy matrix) contains the correct output labels for m training examples\n",
    "        y_hat:(numpy matrix) contains the sigmoid output values for m training examples\n",
    "        learning_rate: (float) learning rate\n",
    "    Returns:\n",
    "        parameters: (dict) contains the learned weight and bias parameters\n",
    "    '''\n",
    "    # find the derivatives\n",
    "    dw = (1/train_X.shape[1]) * np.dot( train_X, (y_hat - train_y).T )\n",
    "    db = (1/train_X.shape[1]) * np.sum( y_hat - train_y ) \n",
    "    \n",
    "    # update the parameters\n",
    "    parameters['W'] = parameters['W'] - (learning_rate * dw)\n",
    "    parameters['b'] = parameters['b'] - (learning_rate * db)\n",
    "   \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train_X, train_y, num_iters, learning_rate):\n",
    "    '''\n",
    "    for training the model by doing steps systematically\n",
    "    \n",
    "    Arguments:\n",
    "        train_X:(numpy matrix) contains the input features for m training examples\n",
    "        train_y:(numpy matrix) contains the correct output labels for m training examples\n",
    "        num_iters: (int) no. of iterations to run \n",
    "        learning_rate: (float) learning rate\n",
    "     Returns:\n",
    "        parameters: (dict) contains the learned weight and bias parameters\n",
    "        costs: (list) contains cost per 100 iterations\n",
    "    '''\n",
    "    \n",
    "    parameters = initialize_parameters(train_X.shape[0])\n",
    "    \n",
    "    # for storing cost\n",
    "    costs = []\n",
    "    \n",
    "    for iter in range(num_iters):\n",
    "        z = np.dot(parameters['W'].T, train_X) + parameters['b']\n",
    "        y_hat = sigmoid(z)\n",
    "        J = compute_cost(train_y, y_hat)\n",
    "   \n",
    "        costs.append(J)\n",
    "        parameters = gradient_descent(parameters, train_X, train_y, y_hat, learning_rate)\n",
    "        \n",
    "        if iter % 100 == 0:\n",
    "            print('Cost after iteration %i: %f'%(iter,J))\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.584508\n",
      "Cost after iteration 200: 0.466949\n",
      "Cost after iteration 300: 0.376007\n",
      "Cost after iteration 400: 0.331463\n",
      "Cost after iteration 500: 0.303273\n",
      "Cost after iteration 600: 0.279880\n",
      "Cost after iteration 700: 0.260042\n",
      "Cost after iteration 800: 0.242941\n",
      "Cost after iteration 900: 0.228004\n",
      "Cost after iteration 1000: 0.214820\n",
      "Cost after iteration 1100: 0.203078\n",
      "Cost after iteration 1200: 0.192544\n",
      "Cost after iteration 1300: 0.183033\n",
      "Cost after iteration 1400: 0.174399\n",
      "Cost after iteration 1500: 0.166521\n",
      "Cost after iteration 1600: 0.159305\n",
      "Cost after iteration 1700: 0.152667\n",
      "Cost after iteration 1800: 0.146542\n",
      "Cost after iteration 1900: 0.140872\n"
     ]
    }
   ],
   "source": [
    "num_iters = 2000\n",
    "learning_rate = 0.005\n",
    "# train the model to find the weights\n",
    "parameters, costs = model(train_X, train_y, num_iters, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(features_X, parameters):\n",
    "    '''\n",
    "    for predicting the output labels for inputs\n",
    "    \n",
    "    Arguments:\n",
    "        feature_X: (numpy matrix) contains the input features for m training examples\n",
    "        parameters: (dict) contains the learned weight and bias parameters\n",
    "    Returns:\n",
    "        pred: (numpy array) output labels\n",
    "    '''\n",
    "    # find the output of logistic regression\n",
    "    z = np.dot(parameters['W'].T, features_X) + parameters['b']\n",
    "    # compute the sigmoid output\n",
    "    pred = sigmoid(z)\n",
    "    \n",
    "    # if the output is >0.5 then we consider that the picture is of a cat else it is a non-cat picture. \n",
    "    pred = (pred > 0.5)\n",
    "    \n",
    "    return pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_train = predict(train_X, parameters)\n",
    "prediction_test = predict(test_X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.04306220095694 %\n",
      "test accuracy: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "# Print train/test Errors\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(prediction_train - train_y)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(prediction_test - test_y)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba00f949b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(costs, learning_rate):\n",
    "    '''\n",
    "    for plotting learning curve\n",
    "    \n",
    "    Arguments:\n",
    "        costs: (list) contains the costs per 100 iterations\n",
    "        learning_rate: (float) learning rate\n",
    "    Returns:\n",
    "        nil\n",
    "    '''\n",
    "    # Plot learning curve( cost vs iterations)\n",
    "    costs = np.squeeze(costs)\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
